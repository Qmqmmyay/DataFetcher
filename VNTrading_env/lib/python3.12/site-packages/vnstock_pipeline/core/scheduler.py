"""
Điều phối quá trình xử lý dữ liệu cho danh sách mã chứng khoán.

Quy trình:
  1. Với mỗi mã chứng khoán, thực hiện:
     - (Tùy chọn) Xem trước dữ liệu đã xuất.
     - Fetch dữ liệu, Validate, Transform, Export.
     - Nếu có lỗi, retry theo số lần quy định.
  2. Nếu số mã > 10, sử dụng xử lý song song (asynchronous) kết hợp với ThreadPoolExecutor,
     hiển thị tiến trình qua tqdm.
  3. Sau khi hoàn thành, in báo cáo tổng kết (thời gian, tốc độ trung bình, số mã thành công/và thất bại)
     và lưu log lỗi vào file CSV.
"""

import time
import csv
import logging
from typing import List, Optional, Dict, Any
from concurrent.futures import ThreadPoolExecutor
import asyncio

from tqdm import tqdm

logger = logging.getLogger(__name__)

def in_jupyter() -> bool:
    """
    Kiểm tra xem chương trình có đang chạy trong Jupyter Notebook không.
    """
    try:
        shell = get_ipython().__class__.__name__
        return shell == "ZMQInteractiveShell"
    except NameError:
        return False

class Scheduler:
    def __init__(self, 
                 fetcher: "Fetcher",
                 validator: "Validator",
                 transformer: "Transformer",
                 exporter: Optional["Exporter"] = None,
                 retry_attempts: int = 3,
                 backoff_factor: float = 2.0):
        """
        Khởi tạo Scheduler với các thành phần xử lý dữ liệu.
        
        :param fetcher: Đối tượng fetcher (lấy dữ liệu).
        :param validator: Đối tượng validator (kiểm tra dữ liệu).
        :param transformer: Đối tượng transformer (chuyển đổi dữ liệu).
        :param exporter: Đối tượng exporter (xuất dữ liệu).
        :param retry_attempts: Số lần thử lại tối đa.
        :param backoff_factor: Hệ số chờ giữa các lần retry.
        """
        self.fetcher = fetcher
        self.validator = validator
        self.transformer = transformer
        self.exporter = exporter
        self.retry_attempts = retry_attempts
        self.backoff_factor = backoff_factor

    def process_ticker(self, ticker: str) -> None:
        """
        Xử lý dữ liệu cho một mã chứng khoán: fetch → validate → transform → export.
        Thực hiện retry nếu có lỗi.
        
        :param ticker: Mã chứng khoán cần xử lý.
        """
        attempt = 0
        success = False
        while attempt < self.retry_attempts and not success:
            attempt += 1
            try:
                # Nếu exporter hỗ trợ preview, lấy dữ liệu xem trước (optional)
                cached_data = self.exporter.preview(ticker, n=5) if self.exporter and hasattr(self.exporter, "preview") else None

                raw_data = self.fetcher.fetch(ticker)
                if not self.validator.validate(raw_data):
                    raise ValueError(f"Validation failed for {ticker}.")
                
                transformed_data = self.transformer.transform(raw_data)
                if self.exporter:
                    self.exporter.export(transformed_data, ticker)
                success = True
                logger.info(f"[{ticker}] Successfully processed on attempt {attempt}.")
            except Exception as e:
                logger.warning(f"[{ticker}] Attempt {attempt} failed with error: {e}")
                if attempt < self.retry_attempts:
                    time.sleep(self.backoff_factor ** attempt)
                else:
                    raise e

    async def _run_async(self, tickers: List[str]) -> Dict[str, Any]:
        """
        Thực thi xử lý các ticker song song sử dụng asyncio và ThreadPoolExecutor.
        Hiển thị tiến trình qua tqdm.
        
        :param tickers: Danh sách mã chứng khoán.
        :return: Bản tóm tắt kết quả.
        """
        overall_success = 0
        overall_fail = 0
        errors = []
        start_time = time.time()
        tasks = []
        ticker_map = {}
        max_workers = 10
        loop = asyncio.get_event_loop()
        executor = ThreadPoolExecutor(max_workers=max_workers)
        for ticker in tickers:
            future = loop.run_in_executor(executor, self.process_ticker, ticker)
            tasks.append(future)
            ticker_map[future] = ticker

        pbar = tqdm(total=len(tasks), desc="Processing tickers")
        for future in asyncio.as_completed(tasks):
            try:
                await future
                overall_success += 1
            except Exception as e:
                overall_fail += 1
                t = ticker_map.get(future, "unknown")
                errors.append((t, str(e)))
                logger.error(f"Ticker {t} failed with error: {e}")
            pbar.update(1)
        pbar.close()
        total_time = time.time() - start_time
        avg_speed = total_time / len(tickers) if tickers else 0
        summary = {
            "success": overall_success,
            "fail": overall_fail,
            "total_time": total_time,
            "avg_speed": avg_speed,
            "errors": errors
        }
        return summary

    def run(self, tickers: List[str]) -> None:
        """
        Chạy quy trình xử lý cho danh sách mã chứng khoán.
        Nếu số mã > 10, sử dụng xử lý song song (asynchronous).
        Hiển thị tiến trình và báo cáo tổng kết khi hoàn thành.
        
        :param tickers: Danh sách mã chứng khoán.
        """
        start_time = time.time()
        num_tickers = len(tickers)
        threshold = 10
        summary = None
        if num_tickers > threshold:
            logger.info("Using parallel processing for tickers.")
            if in_jupyter():
                try:
                    import nest_asyncio
                    nest_asyncio.apply()
                except ImportError:
                    logger.warning("nest_asyncio not installed; running without patch.")
            loop = asyncio.get_event_loop()
            summary = loop.run_until_complete(self._run_async(tickers))
        else:
            logger.info("Processing tickers sequentially.")
            overall_success = 0
            overall_fail = 0
            errors = []
            for ticker in tqdm(tickers, desc="Processing tickers"):
                try:
                    self.process_ticker(ticker)
                    overall_success += 1
                except Exception as e:
                    overall_fail += 1
                    errors.append((ticker, str(e)))
                    logger.error(f"Ticker {ticker} failed with error: {e}")
            total_time = time.time() - start_time
            avg_speed = total_time / num_tickers if num_tickers > 0 else 0
            summary = {
                "success": overall_success,
                "fail": overall_fail,
                "total_time": total_time,
                "avg_speed": avg_speed,
                "errors": errors
            }
        print("Scheduler run complete.")
        print(f"Success: {summary['success']}, Fail: {summary['fail']}")
        print(f"Total time: {summary['total_time']:.2f} seconds, Average time per ticker: {summary['avg_speed']:.2f} seconds")
        if summary["errors"]:
            error_file = "error_log.csv"
            with open(error_file, "w", newline="", encoding="utf-8") as f:
                writer = csv.writer(f)
                writer.writerow(["Ticker", "Error"])
                writer.writerows(summary["errors"])
            print(f"Error log saved to {error_file}.")
